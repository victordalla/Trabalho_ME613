---
output: 
  pdf_document:
    fig_crop: no
fontsize: 10pt
documentclass: article
geometry: 
 - a4paper
 - textwidth=18cm
 - textheight=21cm
header-includes:
  - \usepackage[brazil, english, portuguese]{babel}
  - \usepackage[utf8]{inputenc}
  - \usepackage[T1]{fontenc}
  - \usepackage[fixlanguage]{babelbib}
  - \usepackage{times}
  - \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  message = FALSE,
  warning = FALSE,
  fig.align = "center", fig.height = 3, fig.width = 5
  )
options(
  OutDec = ",", 
  digits = 3, 
  knitr.table.format = "latex", 
  xtable.comment = FALSE
  )
```

```{r lib}
library(aod)
library(dplyr)
library(ggplot2)
```


# Questão 5

## Introdução

Um modelo linear simples pode ser definido como $Y_{i}=\beta_{0}+\beta_{1}\left(x_{i}-\overline{x}\right)+\xi_{i}, \ \xi_{i} \stackrel{i . i . d .}{\sim} N\left(0, \sigma^{2}\right)$. Nssa classe de modelos há três suposições: indepedência das observações, distribuição normal e homocedasticidade dos erros (variância constante). O objetivo dessa análise é avaliar como os estimadores de $\beta_0$ e $\beta_1$ se comportam quando cada uma dessas suposições é violada. Isso será abordado através da simulação de 100 valores da resposta segundo alguns critérios considerando três tamanhos amostrais ($n=30, 50, 100$), $\beta_0=1$, $\beta_1=1,5$ e covariável $x$ fixa gerada de uma distribuiçaõ $U(5, 20)$.

```{r}
# tamanhos amostrais
ns <- c(30, 50, 100)
# número de réplicas
r <- 100
# valores verdadeiros
b0 <- 1
b1 <- 1.5
#sigma2 <- 4
mu <- 0
sigma <- 2
nu <- 6
```

```{r}
cobertura_empirica <- function(resultados) {
  group_by(resultados, n) %>% 
    summarise(b0.cobertura = mean(b0 >= b0.lo & b0 <= b0.hi), b1.cobertura = mean(b1 >= b1.lo & b1 <= b1.hi))
}

plot_intervalos <- function(resultados) {
  tidyr::gather(resultados, "par", "est", b0.est, b1.est) %>% 
    ggplot(aes(repl)) + 
    geom_hline(yintercept = b0, col = "cadetblue", linetype = "dashed") +
    geom_ribbon(aes(ymin=b0.lo, ymax=b0.hi), fill = "coral", alpha = 0.5) + 
    facet_grid(par~n) + theme_bw()
}

plot_histograma <- function(resultados) {
  tidyr::gather(resultados, "par", "est", b0.est, b1.est) %>% 
    ggplot(aes(est)) + geom_histogram(bins = 15) + 
    facet_grid(n~par, scales = "free") + theme_bw()
  }
```


## Item a)

$Y_{i}=\beta_{0}+\beta_{1}\left(x_{i}-\overline{x}\right)+\xi_{i}$ onde $\xi_{i} \stackrel{i . i . d .}{\sim} N\left(0, \sigma^{2}\right)$ e $\sigma=2$.

```{r}
resultados <- tibble(
  # tibble recicla, então todas as colunas são de mesmo tamanho mas assim fica mais legível :)
  n = numeric(length(ns) * r), repl = 0,  b0.est = 0, b1.est = 0, 
  b0.lo = 0, b0.hi = 0, b1.lo = 0, b1.hi = 0, pvalor = 0
  )
i <- 0
for (n in ns) {
  x <- runif(n, 5, 20)
  xbar <- mean(x)
  
  for (repl in 1:r) {
    i <- i + 1
    y <- b0 + b1*(x-xbar) + rnorm(n, mu, sigma)
    fit <- lm(y ~ I(x-xbar))
    # fit$coefficients e confint retornam vetores, mas c() sempre tem 1 dimensão :)
    # IMPORTANTE: verificar wald.test
    resultados[i, ] <- c(
      n, repl, fit$coefficients, confint(fit, 1), confint(fit, 2), 
      aod::wald.test(b=coef(fit), Sigma=vcov(fit), Terms=c(1,2), H0=c(1,0), df = 98)$result$chi2[3]
      )
  }
}

```


```{r hist_a, fig.cap="Histograma dos betas para cada tamanho amostral. Item a)\\label{fig:hista}"}
plot_histograma(resultados)
```

A Figura \ref{fig:hist_a} apresenta o histograma dos parâmetros $\beta_0$ e $\beta_1$ obtidos dos 100 ajustes para cada tamanho amostral de do conjuto de covariáveis $x$. Por meio da Figura, nota-se a medida que o tamanho de $n$ aumenta, a variância das estimativas diminui e os valores concentram-se no verdadeiros valores do parâmetro ($\beta_0=1$ e $\beta_1=1,5$). Assim, percebemos a consistência dos estimadores de mínimos quadrados quando todas as suposições do modelo são verificadas.

```{r ic_a, fig.cap="Intervalos de confianca para as estimativas em cada tamanho amostral item a).\\label{fig:ic_a}"}
plot_intervalos(resultados)
```

O comportamento dos intervalos de confiança para $\beta_0$ e $\beta_1$ obtidos dos 100 ajustes do modelo linear assemelha-se com a situação anterior como mostra a Figura \ref{fig:ic_a}, isto é, a medida que o tamanho da amostra cresce, a variabilidade dos intervalos diminui. Assim, os intervalos obtidos quando $n = 100$ possuem menor comprimento.

Os intervalos foram gerados com um coeficiente de $95\%$ de confiança o que representa que, de acordo com a visão frequentista da inferência, quando gerados 100 intervalos deste tipo, em média 95 contém o verdadeiro valor do parâmetro. Assim, a Tabela \ref{tab:cober_a} mostra as probabilidades de cobertura dos intervalos de confiança para cada tamanho amostral. Dessa forma, nota-se que esse valor varia devido à flutuação amostral mas essa variação possui uma magnetude baixa.

\begin{table}[ht]
\centering
\caption{Cobertura empírica dos intervalos de confianca} 
\label{cober_a}
\begin{tabular}{rrr}
  \hline
n & $\beta_0$ & $\beta_1$ \\ 
  \hline
30,00 & 0,97 & 0,96 \\ 
50,00 & 0,95 & 0,95 \\ 
100,00 & 0,94 & 0,99 \\ 
   \hline
\end{tabular}
\end{table} 

```{r}
#cobertura_empirica(resultados) %>%
#  xtable::xtable(label = "cober_a", caption = "Cobertura empírica dos intervalos de confiança")
```

## Item b)

$Y_{i}=\beta_{0}+\beta_{1}\left(x_{i}-\overline{x}\right)+\xi_{i}$, onde $\xi_{i} \stackrel{ind.}{\sim} N\left(0, \sigma^{2} x_i \right)$ e $\sigma=2$.

```{r}
resultados <- tibble(
  # tibble recicla, então todas as colunas são de mesmo tamanho mas assim fica mais legível :)
  n = numeric(length(ns) * r), repl = 0,  b0.est = 0, b1.est = 0, 
  b0.lo = 0, b0.hi = 0, b1.lo = 0, b1.hi = 0, pvalor = 0
  )
i <- 0
for (n in ns) {
  x <- runif(n, 5, 20)
  xbar <- mean(x)
  
  for (repl in 1:r) {
    i <- i + 1
    y <- b0 + b1*(x-xbar) + rnorm(n, mu, x*sigma)
    fit <- lm(y ~ I(x-xbar))
    # fit$coefficients e confint retornam vetores, mas c() sempre tem 1 dimensão :)
    # IMPORTANTE: verificar wald.test
    resultados[i, ] <- c(
      n, repl, fit$coefficients, confint(fit, 1), confint(fit, 2), 
      aod::wald.test(b=coef(fit), Sigma=vcov(fit), Terms=c(1,2), H0=c(1,0))$result$chi2[3]
      )
  }
}

#cobertura_empirica(resultados)
```

```{r}
#plot_intervalos(resultados)
```

```{r}
plot_histograma(resultados)
```

## Item c)

$\xi_{i} \stackrel{i . i . d .}{\sim} t_{(\nu)}\left(\sigma^{2}\right)$, onde  $\nu=6$ e  $\mathcal{V}(\xi)=\sigma^{2} \frac{\nu}{\nu-2}$.

```{r}
resultados <- tibble(
  # tibble recicla, então todas as colunas são de mesmo tamanho mas assim fica mais legível :)
  n = numeric(length(ns) * r), repl = 0,  b0.est = 0, b1.est = 0, 
  b0.lo = 0, b0.hi = 0, b1.lo = 0, b1.hi = 0, pvalor = 0
  )
i <- 0
for (n in ns) {
  x <- runif(n, 5, 20)
  xbar <- mean(x)
  
  for (repl in 1:r) {
    i <- i + 1
    # https://www.rdocumentation.org/packages/LaplacesDemon/versions/16.1.1/topics/dist.Student.t
    # https://en.wikipedia.org/wiki/Student's_t-distribution#Generalized_Student's_t-distribution
    y <- b0 + b1*(x-xbar) + LaplacesDemon::rst(n, mu, sigma, nu)
    fit <- lm(y ~ I(x-xbar))
    # fit$coefficients e confint retornam vetores, mas c() sempre tem 1 dimensão :)
    # IMPORTANTE: verificar wald.test
    resultados[i, ] <- c(
      n, repl, fit$coefficients, confint(fit, 1), confint(fit, 2), 
      aod::wald.test(b=coef(fit), Sigma=vcov(fit), Terms=c(1,2), H0=c(1,0))$result$chi2[3]
      )
  }
}

#cobertura_empirica(resultados)
```

```{r}
#plot_intervalos(resultados)
```

```{r}
plot_histograma(resultados)
```

## Item d)

$Y_{i}=\beta_{0}+\beta_{1}\left(x_{i}-\overline{x}\right)+\xi_{i}$, onde $\xi \stackrel{ind.}{\sim} N_n\left(\mathbf{0}, \boldsymbol{\Sigma}\right)$ e a diagonal de $\boldsymbol{\Sigma}$ vale 4 (variância de cada erro) e todos os outros elementos têm valor 0,90 ($\operatorname{Cor}\left(\xi_{i}, \xi_{j}\right) = 0,90, \ j \neq i$).

```{r}
resultados <- tibble(
  # tibble recicla, então todas as colunas são de mesmo tamanho mas assim fica mais legível :)
  n = numeric(length(ns) * r), repl = 0,  b0.est = 0, b1.est = 0, 
  b0.lo = 0, b0.hi = 0, b1.lo = 0, b1.hi = 0, pvalor = 0
  )
i <- 0
for (n in ns) {
  x <- runif(n, 5, 20)
  xbar <- mean(x)
  m <- matrix(data=0.9 * sigma ^ 2, nrow=n, ncol=n)
  diag(m) <- sigma ^ 2
  for (repl in 1:r) {
    i <- i + 1
    y <- b0 + b1*(x-xbar) + c(mvtnorm::rmvnorm(1, rep(mu, nrow(m)), m))
    fit <- lm(y ~ I(x-xbar))
    # fit$coefficients e confint retornam vetores, mas c() sempre tem 1 dimensão :)
    # IMPORTANTE: verificar wald.test
    resultados[i, ] <- c(
      n, repl, fit$coefficients, confint(fit, 1), confint(fit, 2), 
      aod::wald.test(b=coef(fit), Sigma=vcov(fit), Terms=c(1,2), H0=c(1,0))$result$chi2[3]
      )
  }
}

#cobertura_empirica(resultados)
```

```{r}
#plot_intervalos(resultados)
```

```{r}
plot_histograma(resultados)
```