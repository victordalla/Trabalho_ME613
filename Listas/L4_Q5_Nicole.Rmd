---
output: 
  pdf_document:
    fig_crop: no
fontsize: 10pt
documentclass: article
geometry: 
 - a4paper
 - textwidth=18cm
 - textheight=21cm
header-includes:
  - \usepackage[brazil, english, portuguese]{babel}
  - \usepackage[utf8]{inputenc}
  - \usepackage[T1]{fontenc}
  - \usepackage[fixlanguage]{babelbib}
  - \usepackage{times}
  - \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  message = FALSE,
  warning = FALSE,
  fig.align = "center", fig.height = 3, fig.width = 5
  )
options(
  OutDec = ",", 
  digits = 3, 
  knitr.table.format = "latex", 
  xtable.comment = FALSE
  )
```

```{r lib}
library(aod)
library(dplyr)
library(ggplot2)
library(xtable)
source("test_functions.R")
```


# Questão 5

## Introdução

Um modelo linear simples pode ser definido como $Y_{i}=\beta_{0}+\beta_{1}\left(x_{i}-\overline{x}\right)+\xi_{i}, \ \xi_{i} \stackrel{i . i . d .}{\sim} N\left(0, \sigma^{2}\right)$. Nessa classe de modelos há três suposições: indepedência das observações, normalidade e homocedasticidade dos erros (variância constante). O objetivo dessa análise é avaliar como os estimadores de $\beta_0$ e $\beta_1$ se comportam quando cada uma dessas suposições é violada. Isso será abordado através da simulação de 100 valores da resposta segundo alguns critérios considerando três tamanhos amostrais ($n=30, 50, 100$), $\beta_0=1$, $\beta_1=1,5$ e covariável $x$ fixa gerada de uma distribuição $U(5, 20)$. As ferramentas utilizadas para estudar os estimadores foram os gráficos e as tabelas descritos a seguir.

As Figuras \ref{fig:qqa},\ref{fig:qqb}, \ref{fig:qqc} e \ref{fig:qqd} apresentam à esquerda os gráficos de quantil-quantil dos parâmetros $\beta_0$ e $\beta_1$ obtidos dos 100 ajustes para cada tamanho amostral do conjuto de covariáveis $x$ e os gráficos à direita trazem a densidade empírica dos estimadores obtida dos 100 ajustes para cada tamanho da amostra de $x$.

Os intervalos de confiança foram gerados com um coeficiente de $\gamma =95\%$ de confiança. Isso representa que, de acordo com a inferência frequentista, quando gerados 100 intervalos deste tipo, em média, 95 contém o verdadeiro valor do parâmetro. Assim, as Tabelas \ref{tab:cober_a}, \ref{tab:cober_b}, \ref{tab:cober_c} e \ref{tab:cober_d}  mostram as probabilidades de cobertura dos intervalos de confiança para cada tamanho amostral. Já as Figuras \ref{fig:ic_a}, \ref{fig:ic_b}, \ref{fig:ic_c} e \ref{fig:ic_d} representam os intervalos de confiança para as estimativas obtidas a cada réplica e para os três tamanhos amostrais.

Por fim, as tabelas xx, xx, xx e xx apresentam os níveis descritivos empíricos dos testes $H_{0} : \beta_{0}=1$ vs $H_{1} : \beta_{0} \neq 1$ e $H_{0} : \beta_{1}=0$ vs $H_{1} : \beta_{1} \neq 0$ a um nível de significância $\alpha = 0,05$. Para testar as hipóteses acima utilizamos o teste do tipo Wald ($C \beta=M$). (detalhes em https://www.ime.unicamp.br/~cnaber/aula_Intro_MRLM_REG_1S_2019_parte_3_Teste_CB.pdf).


```{r constantes}
# tamanhos amostrais
ns <- c(30, 50, 100)
# número de réplicas
r <- 100
# valores verdadeiros
b0 <- 1
b1 <- 1.5
#sigma2 <- 4
mu <- 0
sigma <- 2
nu <- 6
```

```{r funcoes}
cobertura_empirica_ic <- function(resultados) {
  group_by(resultados, n) %>% 
    summarise(b0.cobertura = mean(b0 >= b0.lo & b0 <= b0.hi), b1.cobertura = mean(b1 >= b1.lo & b1 <= b1.hi))
}

cobertura_empirica_teste <- function(resultados) {
  group_by(resultados, n) %>% 
    summarise(nivel = sum(pvalor < 0.05)/n()) #proporcao de vezes que rejeito h0
}

plot_intervalos <- function(resultados) {
  tidyr::gather(resultados, "par", "est", b0.est, b1.est) %>% 
    ggplot(aes(repl)) + 
    geom_hline(yintercept = b0, col = "cadetblue", linetype = "dashed") +
    geom_ribbon(aes(ymin=b0.lo, ymax=b0.hi), fill = "coral", alpha = 0.5) + 
    facet_grid(par~n) +
    labs(x = "Replicações") +
    theme_bw()
}

plot_qq <- function(resultados, binwidth = NULL, bins = NULL) {
  tidyr::gather(resultados, "par", "est", b0.est, b1.est) %>% 
    ggplot(aes(sample = est)) + stat_qq() + stat_qq_line() +
    facet_grid(n~par, scales = "free") + 
    labs(x = "Teórico", y = "Amostra") +
    theme_bw()
  }

plot_density <- function(resultados) {
  tidyr::gather(resultados, "par", "est", b0.est, b1.est) %>% 
    ggplot(aes(est)) + geom_density() + 
    facet_grid(n~par, scales = "free") + 
    labs(x = "Estimadores", y = "Densidade") +
    theme_bw()
  }
```


## Item a)

Neste item, todas as suposições que o modelo de regressão normal homocedástico possui são verificadas, ou seja, $Y_{i}=\beta_{0}+\beta_{1}\left(x_{i}-\overline{x}\right)+\xi_{i}$ onde $\xi_{i} \stackrel{i . i . d .}{\sim} N\left(0, \sigma^{2}\right)$ e $\sigma=2$. Assim, os resultadores serão apresentados por meio das ferramentas descritas anteriormente. 

```{r result_a}
resultados <- tibble(
  # tibble recicla, então todas as colunas são de mesmo tamanho mas assim fica mais legível :)
  n = numeric(length(ns) * r), repl = 0,  b0.est = 0, b1.est = 0, 
  b0.lo = 0, b0.hi = 0, b1.lo = 0, b1.hi = 0, pvalor = 0
  )
i <- 0
c <- matrix(c(1,0,0,1), byrow = FALSE, nrow = 2)
m <- matrix(c(1,0), nrow = 2)


for (n in ns) {
  x <- runif(n, 5, 20)
  xbar <- mean(x)
  
  for (repl in 1:r) {
    i <- i + 1
    y <- b0 + b1*(x-xbar) + rnorm(n, mu, sigma)
    fit <- lm(y ~ I(x-xbar))
    # fit$coefficients e confint retornam vetores, mas c() sempre tem 1 dimensão :)
    # IMPORTANTE: verificar wald.test
    resultados[i, ] <- c(
      n, repl, fit$coefficients, confint(fit, 1), confint(fit, 2), 
      testeF.CBM(fit.model = fit, m.C = c, m.M = m)
      #aod::wald.test(b=coef(fit), Sigma=vcov(fit), Terms=c(1,2), H0=c(1,0), df = 98)$result$chi2[3]
      )
  }
}

```


```{r qqa, fig.cap="Do lado esquerdo, gráfico de quantil-quantil ds estimadores. À direita está o gráfico com as densidades dos estimadores, ambos para cada tamanho amostral (Item a)\\label{fig:qqa}", fig.width=8, fig.height=4}
q_a <- plot_qq(resultados)
d_a <- plot_density(resultados)

gridExtra::grid.arrange(q_a, d_a, ncol=2)
```

Por meio do gráfico à esquerda da Figura \ref{fig:qqa}, nota-se  que a medida que o tamanho de $n$ aumenta, a variância das estimativas diminui pois os pontos concentram-se em torno da reta. Assim, percebemos a consistência dos estimadores de mínimos quadrados quando todas as suposições do modelo são verificadas. Já pelo gráfico da direita, constatou-se que a distribuição do estimador de $\beta_1$ assemelha-se a uma distribuição normal quando $n$ cresce porém ambas distribuições empíricas são assimétricas.
 
```{r ic_a, fig.cap="Intervalos de confianca para as estimativas em cada tamanho amostral item a).\\label{fig:ic_a}"}
plot_intervalos(resultados)
```

O comportamento dos intervalos de confiança para $\beta_0$ e $\beta_1$ obtidos dos 100 ajustes do modelo linear assemelha-se com a situação anterior como mostra a Figura \ref{fig:ic_a}, isto é, a medida que o tamanho da amostra cresce, a variabilidade dos intervalos diminui e os resultados são mais precisos. Assim, os intervalos obtidos quando $n = 100$ possuem menor comprimento. A Tabela \ref{tab:cober_a} indica que a probabilidade de cobertura dos intervalos de confiança para as estimativas é bem próxima do valor verdadeiro ($95\%$) e, apesar de existir uma flutuação amostral, essa variação possui baixa magnetude.

```{r}
#cobertura_empirica_ic(resultados) %>%
# xtable::xtable(label = "cober_a", caption = "Cobertura empírica dos intervalos de confiança")
```

\begin{table}[ht]
\centering
\caption{Cobertura empírica dos intervalos de confiança para $\beta_0$ e $\beta_1$ do Item a} 
\label{cober_a}
\begin{tabular}{rrr}
  \hline
n & $\beta_0$ & $\beta_1$ \\ 
  \hline
30 & 0,95 & 0,98 \\ 
50 & 0,94 & 0,94 \\ 
100 & 0,91 & 0,95 \\ 
   \hline
\end{tabular}
\end{table}

```{r}
#cobertura_empirica_teste(resultados) %>%
#  xtable::xtable(label = "cober_ta", caption = "Cobertura empírica dos testes")
```

É possível notar por meio da Tabela \ref{tab:cober_ta} que o p-valor obtido nos teste foi sempre menor que o nível de significância $\alpha$. Logo, em todas as simulações rejeitamos a hipótese nula em favor da alternativa.

## Item b)

Nesse item, iremos estudar o comportamento dos estimadores quando apenas a suposição de homocedasticidade não é verificada, isto é, 
$Y_{i}=\beta_{0}+\beta_{1}\left(x_{i}-\overline{x}\right)+\xi_{i}$, onde $\xi_{i} \stackrel{ind.}{\sim} N\left(0, \sigma^{2} x_i \right)$ e $\sigma=2$.

```{r}
resultados <- tibble(
  # tibble recicla, então todas as colunas são de mesmo tamanho mas assim fica mais legível :)
  n = numeric(length(ns) * r), repl = 0,  b0.est = 0, b1.est = 0, 
  b0.lo = 0, b0.hi = 0, b1.lo = 0, b1.hi = 0, pvalor = 0
  )
i <- 0
for (n in ns) {
  x <- runif(n, 5, 20)
  xbar <- mean(x)
  
  for (repl in 1:r) {
    i <- i + 1
    y <- b0 + b1*(x-xbar) + rnorm(n, mu, x*sigma)
    fit <- lm(y ~ I(x-xbar))
    # fit$coefficients e confint retornam vetores, mas c() sempre tem 1 dimensão :)
    # IMPORTANTE: verificar wald.test
    resultados[i, ] <- c(
      n, repl, fit$coefficients, confint(fit, 1), confint(fit, 2), 
      testeF.CBM(fit.model = fit, m.C = c, m.M = m))
  }
}

#cobertura_empirica(resultados)
```

Ao analisar os gráficos de quantil-quantil apresentados na Figura \ref{fig:qqb} pode-se observar que distribução do estimador $\beta_0$ encontra-se um pouco afastada da reta nas caudas indicando caudas pesadas e esse comportamento não altera-se a medida que $n$ cresce. Tal fato é reforçado por meio do gráfico de densidade dos estimadores presente na Figura \ref{fig:qqb}. O comportamento do estimador de $\beta_1$ não se altera tanto quando a suposição de homocedasticidade não é verificada.

```{r qqb, fig.cap="Do lado esquerdo, gráfico de quantil-quantil ds estimadores. À direita está o gráfico com as densidades dos estimadores, ambos para cada tamanho amostral (Item b)\\label{fig:qqb}", fig.width=8, fig.height=4}
q_b <- plot_qq(resultados)
d_b <- plot_density(resultados)

gridExtra::grid.arrange(q_b, d_b, ncol=2)
```

Observa-se que, quando os gráficos da Figura \ref{fig:ic_b} são comparados com a Figura \ref{fig:ic_a}, eles apresentam semelhança no sentido de diminuição no tamanho do intervalo a medida que $n$ cresce. Porém, a variância dos intervalos é maior comparado aos intervalos do Item a.Nota-se através da Tabela \ref{tab:cober_b} que a probabilidade de cobertura do intervalo de confiança para as estimativas é bem próxima do valor verdadeiro ($95\%$) assim como foi observado no Item a.

```{r ic_b, fig.cap="Intervalos de confianca para as estimativas em cada tamanho amostral item b).\\label{fig:ic_b}"}
plot_intervalos(resultados)
```

\begin{table}[ht]
\centering
\caption{Cobertura empírica dos intervalos de confiança para o Item b} 
\label{cober_b}
\begin{tabular}{rrr}
  \hline
n & $\beta_0$ & $\beta_1$ \\ 
  \hline
30,00 & 0,97 & 0,96 \\ 
50,00 & 0,99 & 0,97 \\ 
100,00 & 0,95 & 0,94 \\ 
   \hline
\end{tabular}
\end{table}

```{r}
#cobertura_empirica_ic(resultados) %>%
# xtable(label = "cober_b", caption = "Cobertura empírica dos intervalos de confiança para o Item b")
```

```{r}
#cobertura_empirica_teste(resultados) %>%
#xtable::xtable(label = "cober_tb", caption = "Cobertura empírica dos testes,item b", digits = 3)
```

É possível notar por meio da Tabela x que o p-valor obtido nos teste foi sempre menor que o nível de significância $\alpha$. Logo, em todas as simulações rejeitamos a hipótese nula em favor da alternativa.

## Item c)

Nesse item, iremos estudar o comportamento dos estimadores quando a suposição de normalidade não é verificada, isto é, 
$\xi_{i} \stackrel{i . i . d .}{\sim} t_{(\nu)}\left(\sigma^{2}\right)$, onde  $\nu=6$ e  $\mathcal{V}(\xi)=\sigma^{2} \frac{\nu}{\nu-2}$.

```{r}
resultados <- tibble(
  # tibble recicla, então todas as colunas são de mesmo tamanho mas assim fica mais legível :)
  n = numeric(length(ns) * r), repl = 0,  b0.est = 0, b1.est = 0, 
  b0.lo = 0, b0.hi = 0, b1.lo = 0, b1.hi = 0, pvalor = 0
  )
i <- 0
for (n in ns) {
  x <- runif(n, 5, 20)
  xbar <- mean(x)
  
  for (repl in 1:r) {
    i <- i + 1
    # https://www.rdocumentation.org/packages/LaplacesDemon/versions/16.1.1/topics/dist.Student.t
    # https://en.wikipedia.org/wiki/Student's_t-distribution#Generalized_Student's_t-distribution
    y <- b0 + b1*(x-xbar) + LaplacesDemon::rst(n, mu, sigma, nu)
    fit <- lm(y ~ I(x-xbar))
    # fit$coefficients e confint retornam vetores, mas c() sempre tem 1 dimensão :)
    # IMPORTANTE: verificar wald.test
    resultados[i, ] <- c(
      n, repl, fit$coefficients, confint(fit, 1), confint(fit, 2), 
      testeF.CBM(fit.model = fit, m.C = c, m.M = m))
  }
}

#cobertura_empirica(resultados)
```

Ao analisar os gráficos de quantil-quantil apresentados na Figura \ref{fig:qqc} podemos observar que distribução de $\beta1$ não variam muito conforme $n$ cresce. Já o estimador $\beta_0$ apresenta um comportamento instável quando $n = 30$ já que os pontos se distanciam da reta. Mas, os gráficos de densidade apontem que há uma redução significativa de assimetria conforme aumenta o tamanho da amostra.

```{r qqc, fig.cap="Do lado esquerdo, gráfico de quantil-quantil ds estimadores. À direita está o gráfico com as densidades dos estimadores, ambos para cada tamanho amostral (Item c)\\label{fig:qqc}", fig.width=8, fig.height=4}
q_c <- plot_qq(resultados)
d_c <- plot_density(resultados)

gridExtra::grid.arrange(q_c, d_c, ncol=2)
```

Os resultados apresentados na Figura \ref{fig:ic_c} revelam que não há mudanças significativas no comportamento dos intervalos comparado aos gráficos da Figura \ref{fig:ic_b} assim como não há mudanças significativa na probabilidade de cobertura dos intervalos, como mostra a Tabela \ref{tab:cober_c}.

```{r ic_c, fig.cap="Intervalos de confianca para as estimativas em cada tamanho amostral item c).\\label{fig:ic_c}"}
plot_intervalos(resultados)
```
\begin{table}[ht]
\centering
\caption{Cobertura empírica dos intervalos de confiança item c)} 
\label{cober_c}
\begin{tabular}{rrrr}
  \hline
 & n & b0.cobertura & b1.cobertura \\ 
  \hline
1 & 30,00 & 0,93 & 0,95 \\ 
  2 & 50,00 & 0,96 & 0,95 \\ 
  3 & 100,00 & 0,96 & 0,96 \\ 
   \hline
\end{tabular}
\end{table}

```{r}
#cobertura_empirica_ic(resultados) %>%
# xtable::xtable(label = "cober_c", caption = "Cobertura empírica dos intervalos de confiança item c)")
```

\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 & n & cobertura \\ 
  \hline
1 & 30,00 & 0,00 \\ 
  2 & 50,00 & 0,00 \\ 
  3 & 100,00 & 0,00 \\ 
   \hline
\end{tabular}
\caption{Cobertura empírica dos testes,item c} 
\label{cober_tc}
\end{table}

```{r}
#cobertura_empirica_teste(resultados) %>%
#  xtable::xtable(label = "cober_tc", caption = "Cobertura empírica dos testes,item c")
```

É possível notar por meio da Tabela \ref{tab:cober_tc} que o p-valor obtido nos teste foi sempre menor que o nível de significância $\alpha$. Logo, em todas as simulações rejeitamos a hipótese nula em favor da alternativa.

## Item d)

$Y_{i}=\beta_{0}+\beta_{1}\left(x_{i}-\overline{x}\right)+\xi_{i}$, onde $\xi \stackrel{ind.}{\sim} N_n\left(\mathbf{0}, \boldsymbol{\Sigma}\right)$ e a diagonal de $\boldsymbol{\Sigma}$ vale 4 (variância de cada erro) e todos os outros elementos têm valor 0,90 ($\operatorname{Cor}\left(\xi_{i}, \xi_{j}\right) = 0,90, \ j \neq i$).

```{r}
resultados <- tibble(
  # tibble recicla, então todas as colunas são de mesmo tamanho mas assim fica mais legível :)
  n = numeric(length(ns) * r), repl = 0,  b0.est = 0, b1.est = 0, 
  b0.lo = 0, b0.hi = 0, b1.lo = 0, b1.hi = 0, pvalor = 0
  )
i <- 0
for (n in ns) {
  x <- runif(n, 5, 20)
  xbar <- mean(x)
  M <- matrix(data=0.9 * sigma ^ 2, nrow=n, ncol=n)
  diag(m) <- sigma ^ 2
  for (repl in 1:r) {
    i <- i + 1
    y <- b0 + b1*(x-xbar) + c(mvtnorm::rmvnorm(1, rep(mu, nrow(M)), M))
    fit <- lm(y ~ I(x-xbar))
    # fit$coefficients e confint retornam vetores, mas c() sempre tem 1 dimensão :)
    # IMPORTANTE: verificar wald.test
    resultados[i, ] <- c(
      n, repl, fit$coefficients, confint(fit, 1), confint(fit, 2), 
      testeF.CBM(fit.model = fit, m.C = c, m.M = m)
      )
  }
}

#cobertura_empirica(resultados)
```

```{r qqd, fig.cap="Do lado esquerdo, gráfico de quantil-quantil ds estimadores. À direita está o gráfico com as densidades dos estimadores, ambos para cada tamanho amostral (Item d)\\label{fig:qqd}", fig.width=8, fig.height=4}
q_d <- plot_qq(resultados)
d_d <- plot_density(resultados)

gridExtra::grid.arrange(q_d, d_d, ncol=2)
```

```{r ic_d, fig.cap="Intervalos de confianca para as estimativas em cada tamanho amostral item d).\\label{fig:ic_d}"}
plot_intervalos(resultados)
```

```{r}
#cobertura_empirica_ic(resultados) %>%
# xtable(label = "cober_d", caption = "Cobertura empírica dos intervalos de confiança item d)")
```

```{r}
#cobertura_empirica_teste(resultados) %>%
#  xtable::xtable(label = "cober_td", caption = "Cobertura empírica dos testes,item d")
```