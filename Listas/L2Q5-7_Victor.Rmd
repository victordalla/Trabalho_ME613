---
title: "Lista 2 - Questão 5-7"
author: "Victor D P Cunha"
date: "14 April 2019"
output:
  pdf_document: 
    fig_caption: yes
    fig_crop: no
  html_document:
    df_print: paged
geometry: margin=2cm
header-includes:
  - \usepackage[brazil, english, portuguese]{babel}
  - \usepackage[utf8]{inputenc}
  - \usepackage[T1]{fontenc}
  - \usepackage[fixlanguage]{babelbib}
  - \usepackage{times}

  - \usepackage{graphicx}
  - \usepackage{wrapfig}
  - \usepackage{pdfpages}
  
  - \usepackage{amsfonts}
  - \usepackage{amssymb}
  - \usepackage{amsmath}
  
  - \usepackage{fancyhdr}
  - \usepackage{subcaption}
  - \usepackage{booktabs}
  - \usepackage{caption}
  - \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  message = FALSE,
  warning = FALSE,
  tidy.opts = list(width.cutoff = 60),
  tidy = TRUE
  )
options(
  OutDec = ",", 
  knitr.table.format = "latex", 
  xtable.comment = FALSE
  )
```

```{r lib}
library(ggplot2)
library(ggrepel)
library(magrittr)
library(broom)
library(dplyr)
```


# 5

## a)

```{r 5-import, echo=FALSE}
df <- read.table(
  header = FALSE, 
  col.names = c("Estado", "Escolaridade", "Renda"), 
  text = "
  RR 5.7  685
AP 6.0  683 
AC 4.5  526
RO 4.9  662 
PA 4.7  536 
AM 5.5  627 
TO 4.5  520 
PB 3.9  423 
MA 3.6  343 
RN 4.5  513 
SE 4.3  462 
PI 3.5  383 
BA 4.1  460 
PE 4.6  517 
AL 3.7  454 
CE 4.0  448 
SP 6.8 1076 
RJ 7.1  970 
ES 5.7  722 
MG 5.4  681 
SC 6.3  814 
RS 6.4  800 
PR 6.0  782 
MT 5.4  775 
GO 5.5  689 
MS 5.7  731 
DF 8.2 1499
  ")
```

```{r 5-explore}
ggplot(df, aes(Escolaridade, Renda)) + 
  geom_point(shape = 21, col = "azure4", fill = "azure3") + 
  geom_label_repel(aes(label = Estado))
```

## b)

\[
Y = X\beta + \epsilon
\]

Onde $Y$ é a renda, $\beta = (\beta_0, \beta_1)$ é a renda média com nenhuma escolaridade e o incremento na renda a cada ano a mais estudado, respectivamente, e $X = [1 X_1]$, onde $X_1$ é  a escolaridade.

```{r 5-modelo}
fit <- lm(Renda ~ Escolaridade, data = df)
tidy(fit, conf.int = TRUE) %>% 
  select(-statistic) %>% 
  knitr::kable()
```

Como os p-valores são muito pequenos, concluimos que $\beta_0$ e $\beta_1$ são diferentes de zero, ou seja, são relevantes para o modelo. No entanto, $beta_0$ é negativo, o que não faz sentido. Por isso, considere o mesmo modelo, agora com $X_1$ sendo a escolaridade centrada no zero. Assim, agora $\beta_0$ é a renda média para a escolaridade média.

```{r 5-modelo_reduzido}
df %<>% mutate(Esc_cent = Escolaridade - mean(Escolaridade)) 
fit <- lm(Renda ~ Esc_cent, data = df)
tidy(fit, conf.int = TRUE) %>% 
  select(-statistic) %>% 
  knitr::kable()
```

Como podemos observar pela tabela, $beta_0$ e $\beta_1$ são relevante para o modelo, visto que os testes de hipóteses que testam suas nulidades têm p-valores próximos de zero. Além disso, $\beta_1$ é positivo, o que significa que há uma relação linear positiva entre a escolaridade e a renda média.

## c)

```{r 5-plot}
df <- predict.lm(fit, interval = "prediction") %>% 
  as_tibble() %>% 
  cbind(df)

ggplot(df, aes(Escolaridade, Renda)) + 
  geom_point(col = "cadetblue") + 
  geom_line(aes(y = fit), col = "chocolate") + 
  geom_ribbon(aes(ymin = lwr, ymax = upr), fill = "coral", alpha = 0.3) + 
  geom_text_repel(aes(label = Estado), col = "dimgray") + 
  theme_bw()

boxplot(residuals.lm(fit))
residuals.lm(fit) %>% mutate(df, Residuo = .) %>% 
  ggplot(aes(Renda, Residuo)) + 
  geom_hline(yintercept = 0, linetype = "dashed", col = "cadetblue") + 
  geom_point(col = "chocolate") + 
  theme_bw()
```

O poder de predição é alto, visto que quase todos os pontos ficaram dentro do intervalo de confiança para os preditos. Através da análise do boxplot dos resíduos, é razoável dizer que eles vieram de uma distribuição normal (no entanto, nada se pode dizer sobre a homocedisticidade). Com base nisso e com a aparente relação linear que o gráfico de dispersão sugere entre a escolaridade e a renda, o modelo de regressão linear simples parece o adquado, considerando os conhecidos até o momento.

# 6

## a)

```{r 6-import, echo=FALSE}
df <- read.table(
  header = FALSE, 
  col.names = c("Imposto", "Area_Ter", "Area_Cons", "Idade", "Preco"), 
  text = "
   4.9176   3.4720   0.9980    42    25.9
 5.0208   3.5310   1.5000    62    29.5
 4.5429   2.2750   1.1750    40    27.9
 4.5573   4.0500   1.2320    54    25.9
 5.0597   4.4550   1.1210    42    29.9
 3.8910   4.4550   0.9880    56    29.9
 5.8980   5.8500   1.2400    51    30.9
 5.6039   9.5200   1.5010    32    28.9
15.4202   9.8000   3.4200    42    84.9
14.4598  12.8000   3.0000    14    82.9
 5.8282   6.4350   1.2250    32    35.9
 5.3003   4.9883   1.5520    30    31.5
 6.2712   5.5200   0.9750    30    31.0
 5.9592   6.6660   1.1210    32    30.9
 5.0500   5.0000   1.0200    46    30.0
 8.2464   5.1500   1.6640    50    36.9
 6.6969   6.9020   1.4880    22    41.9
 7.7841   7.1020   1.3760    17    40.5
 9.0384   7.8000   1.5000    23    43.9
 5.9894   5.5200   1.2560    40    37.5
 7.5422   4.0000   1.6900    22    37.9
 8.7951   9.8900   1.8200    50    44.5
 6.0931   6.7265   1.6520    44    37.9
 8.3607   9.1500   1.7770    48    38.9
 8.1400   8.0000   1.5040     3    36.9
 9.1416   7.3262   1.8310    31    45.8
12.0000   5.0000   1.2000    30    41.0
  ")
```

```{r 6-explore}
GGally::ggcorr(df)
```

Observando o gráfico de correlação acima, concluimos que

i) As variáveis Imposto, Area_Ter e Area_Cons têm forte correlação (linear) com o preço (Preco), o que indica que são boas candidatas a serem usadas num modelo de regressão linear. No entanto, a variável Idade parece não estar correlacionada com o preço.

ii) Existe uma forte correlação (linear) entre as variáveis (explicatórias) Imposto, Area_Ter e Area_Cons. Essa conclusão faz sentido, visto que a área construída não pode ser maior que a área do terreno e que o imposto normalmente tem regras que levam em conta as duas áreas. Isso pode significar perdas na qualidade do modelo (conclusões feitas pelas estimativas dos coeficientes e poder prediditivo). Assim, deve-se procurar uma combinação (linear, por exemplo) dessas variáveis para ser usada no modelo no lugar delas.

## b)

\[
Y = X\beta + \epsilon
\]

Onde $Y$ é o preço. $X = [1 \ X_1 ... X_4]$, em que $X_i, i = 1, ..., 4$ são os valores padronizados do imposto, área do terreno, área construída e idade do imóvel, respectivamente. $\beta = (\alpha, \beta_1, ..., \beta_4$, em que $\beta_i, i = 1, ..., 4$ são os coeficientes associados ao imposto, área do terreno, área construída e idade do imóvel, respectivamente; $\alpha$ é o preço médio quando todas as variáveis assumem seu valor médio, visto que não faz sentido falar de preço médio quando as variáveis são nulas.

```{r 6-modelo}
fit <- mutate_at(df, vars(-Preco), function(x) (x - mean(x)) / sd(x)) %$% 
  lm(Preco ~ Imposto + Area_Ter + Area_Cons + Idade)
tidy(fit, conf.int = TRUE) %>% 
  select(-statistic) %>% 
  knitr::kable()
```

Como esperado, a idade do imóvel não impacta no preço do imóvel. No entanto, contrário ao esperado, a área do terreno não impacta o preço nesse  modelo; isso pode ser devido à alta correlação dessa variável com as outras.

```{r 6-modelo_reduzido}
fit <- mutate_at(df, vars(-Preco), function(x) (x - mean(x)) / sd(x)) %$% 
  lm(Preco ~ Imposto + Area_Cons)
tidy(fit, conf.int = TRUE) %>% 
  select(-statistic) %>% 
  knitr::kable()
```

## c)

```{r 6-plot}
df <- predict.lm(fit, interval = "prediction") %>% 
  as_tibble() %>% 
  cbind(df)

ggplot(df, aes(Area_Ter)) + 
  geom_pointrange(aes(y = fit, ymin = lwr, ymax = upr), col = "chocolate", shape = 15, alpha = 0.7) + 
  geom_point(aes(y = Preco), col = "darkviolet", size = 2.5) + 
  theme_bw()

ggplot(df, aes(Preco, fit)) + 
  geom_abline(intercept = 0, slope = 1, col = "chocolate") + 
  geom_point(col = "cadetblue") + 
  theme_bw()

boxplot(residuals.lm(fit))
residuals.lm(fit) %>% mutate(df, Residuo = .) %>% 
  ggplot(aes(Preco, Residuo)) + 
  geom_hline(yintercept = 0, linetype = "dashed", col = "cadetblue") + 
  geom_point(col = "chocolate") + 
  theme_bw()
```

# 7

```{r 7-import, echo=FALSE}
df <- read.table(
  header = FALSE, 
  col.names = c("Etiologia", "Carga", "VO2"), 
  text = "
      CH        64.0       13.40
    CH        71.0       12.70
    ID        27.0       8.80
    ID        82.0       12.20
    IS        38.0       10.70
    CH        47.0       12.90
    ID         3.0       7.30
    IS        41.0       10.20
    ID        48.0       9.70
    CH        97.0       15.30
    ID        55.0       10.50
    CH        49.0       13.20
    CH        95.0       17.10
    CH        23.0       9.70
    IS        80.0       10.80
    CH        66.0       11.30
    CH        64.0       15.80
    CH        85.0       22.80
    IS        45.0       10.70
    ID        75.0       14.30
    ID        95.0       12.90
    ID        48.0       10.60
    CH        55.0       12.80
    CH        41.0       10.50
    CH        86.0       14.30
    CH        66.0       9.50
    ID        64.0       11.50
    ID        125.0      18.40
    ID        82.0       15.60
    ID        13.0       9.60
    ID        97.0       15.80
    IS        68.0       26.00
    ID        47.0       8.60
    CH        75.0       12.20
    ID        105.0      18.20
    CH        127.0      23.60
    ID        97.0       13.00
    IS        65.0       6.90
    ID        64.0       12.10
    CH        157.0      29.80
    CH        71.0       15.10
    ID        60.0       12.80
    CH        97.0       20.70
    IS        52.0       9.30
    IS        85.0       11.30
    IS        85.0       15.80
    IS        14.0       8.60
    IS        85.0       14.60
    ID        95.0       13.40
    CH        60.0       10.99
    ID        73.0       13.81
    ID        30.0       9.81
    CH        55.0       10.40
    ID        67.0       10.30
    ID        60.0       8.24
    CH        70.0       16.61
    ID        90.0       15.35
    ID        47.0       14.50
    ID        37.5       12.96
    IS        115.0      14.90
    IS        40.5       9.50
    CH        82.0       15.10
    IS        47.0       11.40
    IS        75.0       17.20
    IS        47.0       11.30
    IS        75.0       12.80
    IS        105.0      16.00
    IS        95.0       17.30
    IS        54.0       11.20
    IS        43.0       12.70
    IS        71.0       14.00
    ID        78.0       13.10
    ID        56.0       10.90
    IS        25.0       10.00
    CH        125.0      18.70
    CH        42.0       11.10
    ID        103.0      14.80
    IS        85.0       14.10
     C        84.0       14.00
     C        96.0       11.60
     C        85.0       14.50
     C        105.0      22.60
     C        88.0       14.40
     C        88.0       19.40
     C        118.0      21.10
     C        86.0       21.50
     C        92.0       21.70
     C        82.0       13.20
     C        65.0       13.60
     C        71.0       12.66
     C        94.0       16.30
     C        114.0      18.50
     C        86.0       14.90
     C        162.0      20.80
     C        169.0      26.30
     C        150.0      20.10
     C        188.0      24.70
     C        73.0       18.50
     C        74.0       15.60
     C        114.0      15.20
     C        129.0      18.70
     C        187.0      26.30
     C        112.0      15.00
     C        75.0       13.90
     C        115.0      18.30
     C        150.0      22.60
     C        64.0       12.80
     C        94.0       16.00
     C        71.0       12.50
     C        60.0       11.80
     C        67.0       12.70
     C        56.0       11.90
     C        131.0      25.20
     C        171.0      24.50
     C        35.0       11.50
     C        75.0       15.50
     C        124.0      25.30
     C        110.0      21.50
  ")
```

```{r}
ggplot(df, aes(Carga, VO2)) + 
  geom_point(col = "cadetblue") + 
  facet_wrap(~Etiologia) + 
  theme_bw()
```

Pelo gráfico acima, é razoável ajustar o modelo 

\[
Y_i = \alpha + \beta x + \gamma_1 d_1 + \gamma_2 d_2 + \gamma_3 d_3 + \delta_1 xd_1 \delta_2 xd_2 \delta_3 xd_3
\]

Onde "C" é a casela de referência, $d_1, d_2, d_3$ são as indicadoras de "CH", "ID" e "IS", respectivamente.

```{r}
# C é a casela de referência
fit <- mutate(df, Carga = Carga - mean(Carga)) %$% 
  lm(VO2 ~ Carga + Etiologia + Carga * Etiologia)
tidy(fit, conf.int = TRUE) %>% 
  select(-statistic, -std.error) %>% 
  knitr::kable(resultados)
```

```{r}
df %<>% cbind(predict.lm(fit, interval = "prediction"))


filter(resultados, term %in% c("Carga", "Carga:EtiologiaCH", "Carga:EtiologiaID", "Carga:EtiologiaIS")) %>% 
  ggplot(aes(term, estimate)) + 
    geom_pointrange(aes(ymin = conf.low, ymax = conf.high), col = "chocolate") + 
    geom_point(col = "darkviolet", size = 2) + 
    theme_bw()

ggplot(df, aes(Carga, VO2)) + 
  geom_point(col = "cadetblue") + 
  geom_line(aes(y = fit), col = "chocolate") + 
  geom_ribbon(aes(ymin = lwr, ymax = upr), fill = "coral", alpha = 0.3) + 
  facet_wrap(~Etiologia) + 
  theme_bw()
```


